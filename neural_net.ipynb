{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn1.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMxdlhJDoubglndxOqNZOiW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Ru5PM4LZVrL5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1598274496126,"user_tz":-540,"elapsed":874,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}},"outputId":"2388f17f-3ba2-4996-cbaa-6907c03d0172"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jWZ7tybvWbex","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598274496127,"user_tz":-540,"elapsed":869,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}}},"source":["#불러올 파일의 경로를 filename 변수에 저장\n","filename = '/content/drive/My Drive/colab/train.csv'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHlKYzoWfXJm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598274496129,"user_tz":-540,"elapsed":867,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler, LabelBinarizer\n","import xgboost as xgb\n","class FeatureBinarizatorAndScaler:\n","    \"\"\" This class needed for scaling and binarization features\n","    \"\"\"\n","    NUMERICAL_FEATURES = list()\n","    CATEGORICAL_FEATURES = list()\n","    BIN_FEATURES = list()\n","    binarizers = dict()\n","    scalers = dict()\n","\n","    def __init__(self, numerical=list(), categorical=list(), binfeatures = list(), binarizers=dict(), scalers=dict()):\n","        self.NUMERICAL_FEATURES = numerical\n","        self.CATEGORICAL_FEATURES = categorical\n","        self.BIN_FEATURES = binfeatures\n","        self.binarizers = binarizers\n","        self.scalers = scalers\n","\n","    def fit(self, train_set):\n","        for feature in train_set.columns:\n","\n","            if feature.split('_')[-1] == 'cat':\n","                self.CATEGORICAL_FEATURES.append(feature)\n","            elif feature.split('_')[-1] != 'bin':\n","                self.NUMERICAL_FEATURES.append(feature)\n","\n","            else:\n","                self.BIN_FEATURES.append(feature)\n","        for feature in self.NUMERICAL_FEATURES:\n","            scaler = StandardScaler()\n","            self.scalers[feature] = scaler.fit(np.float64(train_set[feature]).reshape((len(train_set[feature]), 1)))\n","        for feature in self.CATEGORICAL_FEATURES:\n","            binarizer = LabelBinarizer()\n","            self.binarizers[feature] = binarizer.fit(train_set[feature])\n","\n","\n","    def transform(self, data):\n","        binarizedAndScaledFeatures = np.empty((0, 0))\n","        for feature in self.NUMERICAL_FEATURES:\n","            if feature == self.NUMERICAL_FEATURES[0]:\n","                binarizedAndScaledFeatures = self.scalers[feature].transform(np.float64(data[feature]).reshape(\n","                    (len(data[feature]), 1)))\n","            else:\n","                binarizedAndScaledFeatures = np.concatenate((\n","                    binarizedAndScaledFeatures,\n","                    self.scalers[feature].transform(np.float64(data[feature]).reshape((len(data[feature]),\n","                                                                                       1)))), axis=1)\n","        for feature in self.CATEGORICAL_FEATURES:\n","\n","            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures,\n","                                                         self.binarizers[feature].transform(data[feature])), axis=1)\n","\n","        for feature in self.BIN_FEATURES:\n","            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures, np.array(data[feature]).reshape((\n","                len(data[feature]), 1))), axis=1)\n","        print(binarizedAndScaledFeatures.shape)\n","        return binarizedAndScaledFeatures"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"YshWw4MWfX5g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598274496129,"user_tz":-540,"elapsed":863,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}}},"source":["def gini(actual, pred, cmpcol=0, sortcol=1):\n","    assert (len(actual) == len(pred))\n","    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n","    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n","    totalLosses = all[:, 0].sum()\n","    giniSum = all[:, 0].cumsum().sum() / totalLosses\n","\n","    giniSum -= (len(actual) + 1) / 2.\n","    return giniSum / len(actual)\n","\n","\n","def gini_normalized(a, p):\n","    return gini(a, p) / gini(a, a)\n","\n","\n","def gini_xgb(preds, dtrain):\n","    labels = dtrain.get_label()\n","    gini_score = gini_normalized(labels, preds)\n","    return [('gini', gini_score)]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKkH9s5-j6Uw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598274496130,"user_tz":-540,"elapsed":859,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}}},"source":["def preproc(X_train):\n","    # Adding new features and deleting features with low importance\n","    multreg = X_train['ps_reg_01'] * X_train['ps_reg_03'] * X_train['ps_reg_02']\n","    ps_car_reg = X_train['ps_car_13'] * X_train['ps_reg_03'] * X_train['ps_car_13']\n","    X_train = X_train.drop(['ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n","                            'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12',\n","                            'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin',\n","                            'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin', 'ps_car_10_cat', 'ps_ind_10_bin',\n","                            'ps_ind_13_bin', 'ps_ind_12_bin'], axis=1)\n","    X_train['mult'] = multreg\n","    X_train['ps_car'] = ps_car_reg\n","    X_train['ps_ind'] = X_train['ps_ind_03'] * X_train['ps_ind_15']\n","    return X_train"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ST2LEQc0SolZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598276130438,"user_tz":-540,"elapsed":1635163,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}},"outputId":"5526e485-5c0f-4bee-ad6a-3c44afa97eb5"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import SGD\n","from keras.initializers import random_uniform\n","\n","import pandas as pd\n","\n","X_train = pd.read_csv('/content/drive/My Drive/colab/train.csv')\n","y_train = X_train['target']\n","X_test = pd.read_csv('/content/drive/My Drive/colab/test.csv')\n","X_test = X_test.drop(['id'], axis=1)\n","X_train = X_train.drop(['id', 'target'], axis = 1)\n","y_train1 = abs(-1+y_train)\n","y_train = pd.concat([y_train, y_train1], axis=1)\n","binarizerandscaler = FeatureBinarizatorAndScaler()\n","binarizerandscaler.fit(X_train)\n","X_train = binarizerandscaler.transform(X_train)\n","X_test = binarizerandscaler.transform(X_test)\n","# y_train = y_train.as_matrix()\n","y_train = y_train.values\n","\n","\n","#hyperparameters\n","input_dimension = 226\n","learning_rate = 0.0025\n","momentum = 0.85\n","hidden_initializer = random_uniform(seed=1)\n","dropout_rate = 0.2\n","\n","\n","# create model\n","model = Sequential()\n","model.add(Dense(128, input_dim=input_dimension, kernel_initializer=hidden_initializer, activation='relu'))\n","model.add(Dropout(dropout_rate))\n","model.add(Dense(64, kernel_initializer=hidden_initializer, activation='relu'))\n","model.add(Dense(2, kernel_initializer=hidden_initializer, activation='softmax'))\n","\n","sgd = SGD(lr=learning_rate, momentum=momentum)\n","model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\n","model.fit(X_train, y_train, epochs=130, batch_size=128)\n","predictions = model.predict_proba(X_test)\n","\n","ans = pd.DataFrame(predictions)\n","ans = ans[0]\n","ans.to_csv('/content/drive/My Drive/colab/nn.csv', index=False)\n","print(\"sucess\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["(595212, 226)\n","(892816, 226)\n","Epoch 1/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1655 - acc: 0.9633\n","Epoch 2/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1537 - acc: 0.9636\n","Epoch 3/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1534 - acc: 0.9636\n","Epoch 4/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1532 - acc: 0.9636\n","Epoch 5/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1531 - acc: 0.9636\n","Epoch 6/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1529 - acc: 0.9636\n","Epoch 7/130\n","4651/4651 [==============================] - 15s 3ms/step - loss: 0.1528 - acc: 0.9636\n","Epoch 8/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1527 - acc: 0.9636\n","Epoch 9/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1527 - acc: 0.9636\n","Epoch 10/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1526 - acc: 0.9636\n","Epoch 11/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1525 - acc: 0.9636\n","Epoch 12/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1525 - acc: 0.9636\n","Epoch 13/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1525 - acc: 0.9636\n","Epoch 14/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1524 - acc: 0.9636\n","Epoch 15/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1524 - acc: 0.9636\n","Epoch 16/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1523 - acc: 0.9636\n","Epoch 17/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1523 - acc: 0.9636\n","Epoch 18/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1522 - acc: 0.9636\n","Epoch 19/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1522 - acc: 0.9636\n","Epoch 20/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1521 - acc: 0.9636\n","Epoch 21/130\n","4651/4651 [==============================] - 15s 3ms/step - loss: 0.1521 - acc: 0.9636\n","Epoch 22/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1520 - acc: 0.9636\n","Epoch 23/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1520 - acc: 0.9636\n","Epoch 24/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1518 - acc: 0.9636\n","Epoch 25/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1518 - acc: 0.9636\n","Epoch 26/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1519 - acc: 0.9636\n","Epoch 27/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1517 - acc: 0.9636\n","Epoch 28/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1516 - acc: 0.9636\n","Epoch 29/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1516 - acc: 0.9636\n","Epoch 30/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1515 - acc: 0.9636\n","Epoch 31/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1515 - acc: 0.9636\n","Epoch 32/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1515 - acc: 0.9636\n","Epoch 33/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1513 - acc: 0.9636\n","Epoch 34/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1514 - acc: 0.9636\n","Epoch 35/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1513 - acc: 0.9636\n","Epoch 36/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1512 - acc: 0.9636\n","Epoch 37/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1511 - acc: 0.9636\n","Epoch 38/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1511 - acc: 0.9636\n","Epoch 39/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1511 - acc: 0.9636\n","Epoch 40/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1511 - acc: 0.9636\n","Epoch 41/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1510 - acc: 0.9636\n","Epoch 42/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1510 - acc: 0.9636\n","Epoch 43/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1509 - acc: 0.9636\n","Epoch 44/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1509 - acc: 0.9636\n","Epoch 45/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1509 - acc: 0.9636\n","Epoch 46/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1508 - acc: 0.9636\n","Epoch 47/130\n","4651/4651 [==============================] - 14s 3ms/step - loss: 0.1508 - acc: 0.9636\n","Epoch 48/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1508 - acc: 0.9636\n","Epoch 49/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1507 - acc: 0.9636\n","Epoch 50/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1507 - acc: 0.9636\n","Epoch 51/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1505 - acc: 0.9636\n","Epoch 52/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1505 - acc: 0.9636\n","Epoch 53/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1506 - acc: 0.9636\n","Epoch 54/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1504 - acc: 0.9636\n","Epoch 55/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1504 - acc: 0.9636\n","Epoch 56/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1504 - acc: 0.9636\n","Epoch 57/130\n","4651/4651 [==============================] - 14s 3ms/step - loss: 0.1504 - acc: 0.9636\n","Epoch 58/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1503 - acc: 0.9636\n","Epoch 59/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1502 - acc: 0.9636\n","Epoch 60/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1502 - acc: 0.9636\n","Epoch 61/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1502 - acc: 0.9636\n","Epoch 62/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1502 - acc: 0.9636\n","Epoch 63/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1501 - acc: 0.9636\n","Epoch 64/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1500 - acc: 0.9636\n","Epoch 65/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1501 - acc: 0.9636\n","Epoch 66/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1500 - acc: 0.9636\n","Epoch 67/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1499 - acc: 0.9636\n","Epoch 68/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1498 - acc: 0.9636\n","Epoch 69/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1498 - acc: 0.9636\n","Epoch 70/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1498 - acc: 0.9636\n","Epoch 71/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1498 - acc: 0.9636\n","Epoch 72/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1498 - acc: 0.9636\n","Epoch 73/130\n","4651/4651 [==============================] - 14s 3ms/step - loss: 0.1497 - acc: 0.9636\n","Epoch 74/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1496 - acc: 0.9636\n","Epoch 75/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1496 - acc: 0.9636\n","Epoch 76/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1496 - acc: 0.9636\n","Epoch 77/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1495 - acc: 0.9636\n","Epoch 78/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1496 - acc: 0.9636\n","Epoch 79/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1495 - acc: 0.9636\n","Epoch 80/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1493 - acc: 0.9636\n","Epoch 81/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1494 - acc: 0.9636\n","Epoch 82/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1493 - acc: 0.9636\n","Epoch 83/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1493 - acc: 0.9636\n","Epoch 84/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1493 - acc: 0.9636\n","Epoch 85/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1493 - acc: 0.9636\n","Epoch 86/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1492 - acc: 0.9636\n","Epoch 87/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1491 - acc: 0.9636\n","Epoch 88/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1490 - acc: 0.9636\n","Epoch 89/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1490 - acc: 0.9636\n","Epoch 90/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1490 - acc: 0.9636\n","Epoch 91/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1490 - acc: 0.9636\n","Epoch 92/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1489 - acc: 0.9636\n","Epoch 93/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1489 - acc: 0.9636\n","Epoch 94/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1489 - acc: 0.9636\n","Epoch 95/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1487 - acc: 0.9636\n","Epoch 96/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1488 - acc: 0.9636\n","Epoch 97/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1487 - acc: 0.9636\n","Epoch 98/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1487 - acc: 0.9636\n","Epoch 99/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1487 - acc: 0.9636\n","Epoch 100/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1486 - acc: 0.9636\n","Epoch 101/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1485 - acc: 0.9636\n","Epoch 102/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1485 - acc: 0.9636\n","Epoch 103/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1485 - acc: 0.9636\n","Epoch 104/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1484 - acc: 0.9636\n","Epoch 105/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1483 - acc: 0.9636\n","Epoch 106/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1484 - acc: 0.9636\n","Epoch 107/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1482 - acc: 0.9636\n","Epoch 108/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1483 - acc: 0.9636\n","Epoch 109/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1482 - acc: 0.9636\n","Epoch 110/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1481 - acc: 0.9636\n","Epoch 111/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1482 - acc: 0.9636\n","Epoch 112/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1480 - acc: 0.9636\n","Epoch 113/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1480 - acc: 0.9636\n","Epoch 114/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1480 - acc: 0.9636\n","Epoch 115/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1480 - acc: 0.9636\n","Epoch 116/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1480 - acc: 0.9636\n","Epoch 117/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1479 - acc: 0.9636\n","Epoch 118/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1478 - acc: 0.9636\n","Epoch 119/130\n","4651/4651 [==============================] - 11s 2ms/step - loss: 0.1478 - acc: 0.9636\n","Epoch 120/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1478 - acc: 0.9636\n","Epoch 121/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1478 - acc: 0.9636\n","Epoch 122/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1477 - acc: 0.9636\n","Epoch 123/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1477 - acc: 0.9636\n","Epoch 124/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1476 - acc: 0.9636\n","Epoch 125/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1476 - acc: 0.9636\n","Epoch 126/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1476 - acc: 0.9636\n","Epoch 127/130\n","4651/4651 [==============================] - 13s 3ms/step - loss: 0.1476 - acc: 0.9636\n","Epoch 128/130\n","4651/4651 [==============================] - 12s 2ms/step - loss: 0.1475 - acc: 0.9636\n","Epoch 129/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1475 - acc: 0.9636\n","Epoch 130/130\n","4651/4651 [==============================] - 12s 3ms/step - loss: 0.1475 - acc: 0.9636\n","WARNING:tensorflow:From <ipython-input-14-b640ece700c6>:41: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n","Instructions for updating:\n","Please use `model.predict()` instead.\n","sucess\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uHrVgy5EfEcg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598276130443,"user_tz":-540,"elapsed":1635162,"user":{"displayName":"서정민","photoUrl":"","userId":"10004465469685874688"}}},"source":[""],"execution_count":14,"outputs":[]}]}