{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망 모델 keras 라이브러리 읽어오기\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import Model\n",
    "\n",
    "# 시간 측정 및 압축파일을 읽어오기 위한 라이브러리\n",
    "from time import time\n",
    "import datetime\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "# 피쳐 엔지니어링을 위한 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터를 읽어온다\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_id = test['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Util functions 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_num_on_cat(train_df, test_df, target_column, group_column):\n",
    "    # train_df : 훈련 데이터\n",
    "    # test_df : 테스트 데이터\n",
    "    # target_column : 통계기반 파생 변수를 생성한 타겟 변수\n",
    "    # group_column : 피봇(pivot)을 수행할 변수\n",
    "    train_df['row_id'] = range(train_df.shape[0])\n",
    "    test_df['row_id'] = range(test_df.shape[0])\n",
    "    train_df['train'] = 1\n",
    "    test_df['train'] = 0\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터를 통합한다\n",
    "    all_df = train_df[['row_id', 'train', target_column, group_column]].append(test_df[['row_id','train', target_column, group_column]])\n",
    "    \n",
    "    # group_column 기반으로 피봇한 target_column의 값을 구한다 \n",
    "    grouped = all_df[[target_column, group_column]].groupby(group_column)\n",
    "\n",
    "    # 빈도(size), 평균(mean), 표준편차(std), 중간값(median), 최대값(max), 최소값(min)을 구한다\n",
    "    the_size = pd.DataFrame(grouped.size()).reset_index()\n",
    "    the_size.columns = [group_column, '%s_size' % target_column]\n",
    "    the_mean = pd.DataFrame(grouped.mean()).reset_index()\n",
    "    the_mean.columns = [group_column, '%s_mean' % target_column]\n",
    "    the_std = pd.DataFrame(grouped.std()).reset_index().fillna(0)\n",
    "    the_std.columns = [group_column, '%s_std' % target_column]\n",
    "    the_median = pd.DataFrame(grouped.median()).reset_index()\n",
    "    the_median.columns = [group_column, '%s_median' % target_column]\n",
    "    the_max = pd.DataFrame(grouped.max()).reset_index()\n",
    "    the_max.columns = [group_column, '%s_max' % target_column]\n",
    "    the_min = pd.DataFrame(grouped.min()).reset_index()\n",
    "    the_min.columns = [group_column, '%s_min' % target_column]\n",
    "\n",
    "    # 통계 기반 파생 변수를 취합한다\n",
    "    the_stats = pd.merge(the_size, the_mean)\n",
    "    the_stats = pd.merge(the_stats, the_std)\n",
    "    the_stats = pd.merge(the_stats, the_median)\n",
    "    the_stats = pd.merge(the_stats, the_max)\n",
    "    the_stats = pd.merge(the_stats, the_min)\n",
    "    all_df = pd.merge(all_df, the_stats, how='left')\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터로 분리하여 반환한다\n",
    "    selected_train = all_df[all_df['train'] == 1]\n",
    "    selected_test = all_df[all_df['train'] == 0]\n",
    "    selected_train.sort_values('row_id', inplace=True)\n",
    "    selected_test.sort_values('row_id', inplace=True)\n",
    "    selected_train.drop([target_column, group_column, 'row_id', 'train'], axis=1, inplace=True)\n",
    "    selected_test.drop([target_column, group_column, 'row_id', 'train'], axis=1, inplace=True)\n",
    "    selected_train, selected_test = np.array(selected_train), np.array(selected_test)\n",
    "    return selected_train, selected_test\n",
    "\n",
    "\n",
    "def interaction_features(train, test, fea1, fea2, prefix):\n",
    "    # train : 훈련 데이터\n",
    "    # test : 테스트 데이터\n",
    "    # fea1, fea2 : 상호 작용을 수행할 변수 이름\n",
    "    # prefix : 파생 변수의 변수 이름\n",
    "\n",
    "    # 두 변수간의 곱셈/나눗셈 상호 작용에 대한 파생 변수를 생성한다\n",
    "    train['inter_{}*'.format(prefix)] = train[fea1] * train[fea2]\n",
    "    train['inter_{}/'.format(prefix)] = train[fea1] / train[fea2]\n",
    "\n",
    "    test['inter_{}*'.format(prefix)] = test[fea1] * test[fea2]\n",
    "    test['inter_{}/'.format(prefix)] = test[fea1] / test[fea2]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimMinyoung\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\KimMinyoung\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\KimMinyoung\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\KimMinyoung\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\KimMinyoung\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수와 이진 변수 이름을 추출한다\n",
    "cat_fea = [x for x in list(train) if 'cat' in x]\n",
    "bin_fea = [x for x in list(train) if 'bin' in x]\n",
    "\n",
    "# 결측값 (-1)의 개수로 missing 파생 변수를 생성한다\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "\n",
    "# 6개 변수에 대하여 상호작용 변수를 생성한다\n",
    "for e, (x, y) in enumerate(combinations(['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01'], 2)):\n",
    "    train, test = interaction_features(train, test, x, y, e)\n",
    "\n",
    "# 수치형 변수, 상호 작용 파생 변수, ind 변수 이름을 추출한다\n",
    "num_features = [c for c in list(train) if ('cat' not in c and 'calc' not in c)]\n",
    "num_features.append('missing')\n",
    "inter_fea = [x for x in list(train) if 'inter' in x]\n",
    "feature_names = list(train)\n",
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "\n",
    "# ind 변수 그룹의 조합을 하나의 문자열 변수로 표현한다\n",
    "count = 0\n",
    "for c in ind_features:\n",
    "    if count == 0:\n",
    "        train['new_ind'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        train['new_ind'] += '_' + train[c].astype(str)\n",
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "count = 0\n",
    "for c in ind_features:\n",
    "    if count == 0:\n",
    "        test['new_ind'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        test['new_ind'] += '_' + test[c].astype(str)\n",
    "\n",
    "# reg 변수 그룹의 조합을 하나의 문자열 변수로 표현한다\n",
    "reg_features = [c for c in feature_names if 'reg' in c]\n",
    "count = 0\n",
    "for c in reg_features:\n",
    "    if count == 0:\n",
    "        train['new_reg'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        train['new_reg'] += '_' + train[c].astype(str)\n",
    "reg_features = [c for c in feature_names if 'reg' in c]\n",
    "count = 0\n",
    "for c in reg_features:\n",
    "    if count == 0:\n",
    "        test['new_reg'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        test['new_reg'] += '_' + test[c].astype(str)\n",
    "\n",
    "# car 변수 그룹의 조합을 하나의 문자열 변수로 표현한다\n",
    "car_features = [c for c in feature_names if 'car' in c]\n",
    "count = 0\n",
    "for c in car_features:\n",
    "    if count == 0:\n",
    "        train['new_car'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        train['new_car'] += '_' + train[c].astype(str)\n",
    "car_features = [c for c in feature_names if 'car' in c]\n",
    "count = 0\n",
    "for c in car_features:\n",
    "    if count == 0:\n",
    "        test['new_car'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        test['new_car'] += '_' + test[c].astype(str)\n",
    "\n",
    "# 범주형 데이터와 수치형 데이터를 따로 관리한다\n",
    "train_cat = train[cat_fea]\n",
    "train_num = train[[x for x in list(train) if x in num_features]]\n",
    "test_cat = test[cat_fea]\n",
    "test_num = test[[x for x in list(train) if x in num_features]]\n",
    "\n",
    "# 범주형 데이터에 LabelEncode()를 수행한다\n",
    "max_cat_values = []\n",
    "for c in cat_fea:\n",
    "    le = LabelEncoder()\n",
    "    x = le.fit_transform(pd.concat([train_cat, test_cat])[c])\n",
    "    train_cat[c] = le.transform(train_cat[c])\n",
    "    test_cat[c] = le.transform(test_cat[c])\n",
    "    max_cat_values.append(np.max(x))\n",
    "\n",
    "# 범주형 변수의 빈도값으로 새로운 파생 변수를 생성한다\n",
    "cat_count_features = []\n",
    "for c in cat_fea + ['new_ind','new_reg','new_car']:\n",
    "    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n",
    "    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n",
    "    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n",
    "    cat_count_features.append('%s_count'%c)\n",
    "\n",
    "# XGBoost 기반 변수를 읽어온다\n",
    "train_fea0, test_fea0 = pickle.load(open(\"features.pk\", \"rb\"))\n",
    "\n",
    "# 수치형 변수의 결측값/이상값을 0으로 대체하고, 범주형 변수와 XGBoost 기반 변수를 통합한다\n",
    "train_list = [train_num.replace([np.inf, -np.inf, np.nan], 0), train[cat_count_features], train_fea0]\n",
    "test_list = [test_num.replace([np.inf, -np.inf, np.nan], 0), test[cat_count_features], test_fea0]\n",
    "\n",
    "# 피봇 기반 기초 통계 파생 변수를 생성한다\n",
    "for t in ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01']:\n",
    "    for g in ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01', 'ps_ind_05_cat']:\n",
    "        if t != g:\n",
    "            # group_column 변수를 기반으로 target_column 값을 피봇한 후, 기초 통계 값을 파생 변수로 추가한다\n",
    "            s_train, s_test = proj_num_on_cat(train, test, target_column=t, group_column=g)\n",
    "            train_list.append(s_train)\n",
    "            test_list.append(s_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>inter_10*</th>\n",
       "      <th>inter_10/</th>\n",
       "      <th>inter_11*</th>\n",
       "      <th>inter_11/</th>\n",
       "      <th>inter_12*</th>\n",
       "      <th>inter_12/</th>\n",
       "      <th>inter_13*</th>\n",
       "      <th>inter_13/</th>\n",
       "      <th>inter_14*</th>\n",
       "      <th>inter_14/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502649</td>\n",
       "      <td>1.025815</td>\n",
       "      <td>1.436141</td>\n",
       "      <td>0.359035</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>22</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612862</td>\n",
       "      <td>0.957597</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522853</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588531</td>\n",
       "      <td>1.201084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595207</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>1.385641</td>\n",
       "      <td>2.078461</td>\n",
       "      <td>0.230940</td>\n",
       "      <td>6.5</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595208</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.243825</td>\n",
       "      <td>1.535586</td>\n",
       "      <td>6.910137</td>\n",
       "      <td>0.276405</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>30</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595209</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593164</td>\n",
       "      <td>0.732301</td>\n",
       "      <td>0.659071</td>\n",
       "      <td>0.659071</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628391</td>\n",
       "      <td>0.775791</td>\n",
       "      <td>3.491060</td>\n",
       "      <td>0.139642</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>60</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595212 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ps_ind_01  ps_ind_03  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "0               2          5              0              1              0   \n",
       "1               1          7              0              0              1   \n",
       "2               5          9              0              0              1   \n",
       "3               0          2              1              0              0   \n",
       "4               0          0              1              0              0   \n",
       "...           ...        ...            ...            ...            ...   \n",
       "595207          3         10              0              0              0   \n",
       "595208          5          3              0              0              0   \n",
       "595209          1         10              1              0              0   \n",
       "595210          5          3              0              0              1   \n",
       "595211          0          8              1              0              0   \n",
       "\n",
       "        ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  \\\n",
       "0                   0              0              0              0   \n",
       "1                   0              0              0              0   \n",
       "2                   0              0              0              0   \n",
       "3                   0              0              0              0   \n",
       "4                   0              0              0              0   \n",
       "...               ...            ...            ...            ...   \n",
       "595207              1              0              0              0   \n",
       "595208              1              0              0              0   \n",
       "595209              0              0              0              0   \n",
       "595210              0              0              0              0   \n",
       "595211              0              0              0              0   \n",
       "\n",
       "        ps_ind_13_bin  ...  inter_10*  inter_10/  inter_11*  inter_11/  \\\n",
       "0                   0  ...   0.502649   1.025815   1.436141   0.359035   \n",
       "1                   0  ...   0.612862   0.957597   0.766078   0.766078   \n",
       "2                   0  ...  -0.000000   0.000000  -5.000000  -0.200000   \n",
       "3                   0  ...   0.522853   0.645497   0.000000   0.000000   \n",
       "4                   0  ...   0.588531   1.201084   0.000000   0.000000   \n",
       "...               ...  ...        ...        ...        ...        ...   \n",
       "595207              0  ...   0.346410   1.385641   2.078461   0.230940   \n",
       "595208              0  ...   1.243825   1.535586   6.910137   0.276405   \n",
       "595209              0  ...   0.593164   0.732301   0.659071   0.659071   \n",
       "595210              0  ...   0.628391   0.775791   3.491060   0.139642   \n",
       "595211              0  ...  -0.100000 -10.000000  -0.000000   0.000000   \n",
       "\n",
       "        inter_12*  inter_12/  inter_13*  inter_13/  inter_14*  inter_14/  \n",
       "0             7.7  15.714286         22   5.500000        1.4   0.350000  \n",
       "1             2.4   3.750000          3   3.000000        0.8   0.800000  \n",
       "2             0.0   0.000000         60   2.400000        0.0   0.000000  \n",
       "3             7.2   8.888889          0   0.000000        0.0   0.000000  \n",
       "4             6.3  12.857143          0   0.000000        0.0   0.000000  \n",
       "...           ...        ...        ...        ...        ...        ...  \n",
       "595207        6.5  26.000000         39   4.333333        1.5   0.166667  \n",
       "595208        5.4   6.666667         30   1.200000        4.5   0.180000  \n",
       "595209       10.8  13.333333         12  12.000000        0.9   0.900000  \n",
       "595210       10.8  13.333333         60   2.400000        4.5   0.180000  \n",
       "595211        0.7  70.000000          0   0.000000        0.0   0.000000  \n",
       "\n",
       "[595212 rows x 54 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여기 시간 오래걸리는 부분!!!!\n",
    "> 다음번 실행할땐 pickle 파일로 불러와서 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전체를 메모리 효율성을 위하여 희소행렬로 변환한다\n",
    "X = sparse.hstack(train_list).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sparse.hstack(test_list).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X.pickle','rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X.pickle','rb') as f:\n",
    "    X_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.vstack([X.toarray(), X_test.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공신경망 학습을 위해 모든 변수값을 -1~1로 Scaling한다\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data)\n",
    "X = scaler.transform(X.toarray())\n",
    "X_test = scaler.transform(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0495746 ,  0.21571156, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.45409799,  0.95643784, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.56059236,  1.69716412, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.45409799,  2.06752726,  1.24163458, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.56059236, -0.52501472, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.95777058,  1.32680098,  1.24163458, ...,  0.09926404,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95777058,  1.32680098, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.05691978,  0.21571156, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.56059236, -0.52501472, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.95777058,  0.21571156,  1.24163458, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.06426495,  0.21571156, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.56793754, -0.15465158, -0.80538994, ...,  0.09926404,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 5., 0., ..., 1., 7., 0.],\n",
       "       [1., 7., 0., ..., 1., 7., 0.],\n",
       "       [5., 9., 0., ..., 1., 7., 0.],\n",
       "       ...,\n",
       "       [0., 5., 1., ..., 1., 7., 0.],\n",
       "       [6., 5., 0., ..., 1., 7., 0.],\n",
       "       [7., 4., 0., ..., 1., 7., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연산량이 많으므로 X, X_test 피클파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('X.pickle', 'wb') as f:\n",
    "    pickle.dump(X, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_test.pickle', 'wb') as f:\n",
    "    pickle.dump(X_test, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595212"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "\n",
    "- flatten = merge(flatten_layers, mode='concat') \n",
    "- 이부분 에러 잡아야함(버전이 안 맞아 수정해야함, 그냥 버전 낮춰서 사용해도 될듯)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "# 2계층 인공 신경망 모델을 정의한다\n",
    "def nn_model():\n",
    "    inputs = []\n",
    "    flatten_layers = []\n",
    "\n",
    "    # 범주형 변수에 대한 Embedding 계층을 정의한다. 모든 범주형 변수는 해당 변수의 최대값(num_c) 크기의 벡터 임베딩을 학습한다.\n",
    "    for e, c in enumerate(cat_fea):\n",
    "        input_c = Input(shape=(1, ), dtype='int32')\n",
    "        num_c = max_cat_values[e]\n",
    "        embed_c = Embedding(\n",
    "            num_c,\n",
    "            6,\n",
    "            input_length=1\n",
    "        )(input_c)\n",
    "        embed_c = Dropout(0.25)(embed_c)\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        inputs.append(input_c)\n",
    "        flatten_layers.append(flatten_c)\n",
    "\n",
    "    # 수치형 변수에 대한 입력 계층을 정의한다\n",
    "    input_num = Input(shape=(X.shape[1],), dtype='float32')\n",
    "    flatten_layers.append(input_num)\n",
    "    inputs.append(input_num)\n",
    "\n",
    "    # 범주형 변수와 수치형 변수를 통합하여 2계층 Fully Connected Layer를 정의한다\n",
    "    flatten = concatenate(flatten_layers)\n",
    "    #flatten = merge(flatten_layers, mode='concat',concat_axis=-1)\n",
    "    #'module' object is not callable\n",
    "\n",
    "    # 1계층은 512 차원을 가지며, PReLU Activation 함수와 BatchNormalization, Dropout 함수를 통과한다\n",
    "    fc1 = Dense(512, init='he_normal')(flatten)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.75)(fc1)\n",
    "\n",
    "    # 2계층은 64 차원을 가진다\n",
    "    fc1 = Dense(64, init='he_normal')(fc1)\n",
    "    fc1 = PReLU()(fc1)\n",
    "    fc1 = BatchNormalization()(fc1)\n",
    "    fc1 = Dropout(0.5)(fc1)\n",
    "\n",
    "    outputs = Dense(1, init='he_normal', activation='sigmoid')(fc1)\n",
    "\n",
    "    # 모델 학습을 수행하는 optimizer와 학습 기준이 되는 loss 함수를 정의한다\n",
    "    model = Model(input = inputs, output = outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold 교차 검증을 수행한다\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "# 모델 학습을 5번의 랜덤 시드로 수행한 후, 평균값을 최종 결과로 얻는다\n",
    "num_seeds = 5\n",
    "begintime = time()\n",
    "\n",
    "# 내부 교차 검증 및 테스트 데이터에 대한 예측값을 저장하기 위한 준비를 한다\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = train_cat.values\n",
    "X_test_cat = test_cat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cat = []\n",
    "for i in range(X_test_cat.shape[1]):\n",
    "    x_test_cat.append(X_test_cat[:, i].reshape(-1, 1))\n",
    "x_test_cat.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-3c90477851ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# 인공 신경망 모델을 정의한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m# 모델을 학습한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr_cat_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxte_cat_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myte\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-52d2101d902b>\u001b[0m in \u001b[0;36mnn_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# 범주형 변수와 수치형 변수를 통합하여 2계층 Fully Connected Layer를 정의한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#flatten = concatenate(flatten_layers)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mflatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'concat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;31m#'module' object is not callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 개수만큼 모델 학습을 수행한다\n",
    "for s in range(num_seeds):\n",
    "    np.random.seed(s)\n",
    "    for (inTr, inTe) in kfold.split(X, train_label):\n",
    "        xtr = X[inTr]\n",
    "        ytr = train_label[inTr]\n",
    "        xte = X[inTe]\n",
    "        yte = train_label[inTe]\n",
    "\n",
    "        xtr_cat = X_cat[inTr]\n",
    "        xte_cat = X_cat[inTe]\n",
    "\n",
    "        # 범주형 데이터를 추출하여, 수치형 데이터와 통합한다\n",
    "        xtr_cat_list, xte_cat_list = [], []\n",
    "        for i in range(xtr_cat.shape[1]):\n",
    "            xtr_cat_list.append(xtr_cat[:, i].reshape(-1, 1))\n",
    "            xte_cat_list.append(xte_cat[:, i].reshape(-1, 1))\n",
    "        xtr_cat_list.append(xtr)\n",
    "        xte_cat_list.append(xte)\n",
    "\n",
    "        # 인공 신경망 모델을 정의한다\n",
    "        model = nn_model()\n",
    "        # 모델을 학습한다\n",
    "        model.fit(xtr_cat_list, ytr, epochs=20, batch_size=512, verbose=2, validation_data=[xte_cat_list, yte])\n",
    "        \n",
    "        # 예측값의 순위를 구하는 함수 get_rank()를 정의한다. Gini 평가 함수는 예측값 간의 순위를 기준으로 평가하기 때문에 최종 평가 점수에 영향을 미치지 않는다.\n",
    "        def get_rank(x):\n",
    "            return pd.Series(x).rank(pct=True).values\n",
    "        \n",
    "        # 내부 교차 검증 데이터에 대한 예측값을 저장한다\n",
    "        cv_train[inTe] += get_rank(model.predict(x=xte_cat_list, batch_size=512, verbose=0)[:, 0])\n",
    "        print(Gini(train_label[inTe], cv_train[inTe]))\n",
    "        \n",
    "        # 테스트 데이터에 대한 예측값을 저장한다\n",
    "        cv_pred += get_rank(model.predict(x=x_test_cat, batch_size=512, verbose=0)[:, 0])\n",
    "\n",
    "    print(Gini(train_label, cv_train / (1. * (s + 1))))\n",
    "    print(str(datetime.timedelta(seconds=time() - begintime)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 최종 예측값을 파일로 저장한다\n",
    "pd.DataFrame({'id': test_id, 'target': get_rank(cv_pred * 1./ (NFOLDS * num_seeds))}).to_csv('wowkeras5_pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPwYhX4jLBfGYpoLGXKn1Vf",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
