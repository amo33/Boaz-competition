{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "D-GGUt6YTbkx",
    "outputId": "750aa95b-e687-4bb0-cd38-b85fcc8297ca",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library Import & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cv_only = True\n",
    "save_cv = True\n",
    "full_train = False\n",
    "\n",
    "path = \"/content/gdrive/My Drive/보아즈미니플젝/\"\n",
    "\n",
    "# train 데이터, test 데이터를 읽어오기\n",
    "train = pd.read_csv(path+'train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "test_id = test['id']\n",
    "\n",
    "# target 변수를 별도로 분리\n",
    "y = train['target'].values\n",
    "# id, target 변수 제거\n",
    "# (train 데이터와 test 데이터를 동일하게 가져가기 위함!)\n",
    "drop_feature = [\n",
    "    'id',\n",
    "    'target'\n",
    "]\n",
    "X = train.drop(drop_feature,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스코어 정의함수\n",
    "def Gini(y_true, y_pred):\n",
    "    # 정답과 예측값의 개수가 동일한지 확인\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # y_pred 오름차순 정렬\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # Lorenz curves 계산\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # 지니계수 계산\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # 정규화\n",
    "    return G_pred * 1. / G_true\n",
    "\n",
    "# LightGBM 모델 학습 과정에서의 평가함수\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파생변수 1 : 결측값 개수\n",
    "- 파생변수 2 : categorical data -> binary data\n",
    "- 파생변수 3 : ind를 포함한 변수들 조합한 new_ind 생성\n",
    "\n",
    "모델 학습에 사용한 변수들\n",
    "- num_features, cat_features\n",
    "- 파생변수2, 파생변수3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# categorical 변수 분리\n",
    "cat_features = [c for c in feature_names if ('cat' in c and 'count' not in c)]\n",
    "# numerical 변수 분리\n",
    "num_features = [c for c in feature_names if ('cat' not in c and 'calc' not in c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수1 : 결측값 개수\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "num_features.append('missing')\n",
    "\n",
    "\n",
    "# 파생변수 2 : 범주형변수를 LabelEncoder()를 통해, numerical로 변환\n",
    "for c in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[c])\n",
    "    train[c] = le.transform(train[c])\n",
    "    test[c] = le.transform(test[c])\n",
    "\n",
    "# 이후 원핫인코더를 통해 고유값 별로 0/1의 binary 변수를 데이터로 사용\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train[cat_features])\n",
    "X_cat = enc.transform(train[cat_features])\n",
    "X_t_cat = enc.transform(test[cat_features])\n",
    "\n",
    "# 파생변수 3 : ind 변수들의 고유값을 조합한 new_ind 변수를 생성\n",
    "# ex) ps_ind01 = 1, ps_ind_02 =0 의 경우 new_ind는 1_2_ 라는 문자열 변수로!\n",
    "# ind 변수들의 조합을 기반으로 파생변수 생성\n",
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "count=0\n",
    "for c in ind_features:\n",
    "    if count==0:\n",
    "        train['new_ind'] = train[c].astype(str)+'_'\n",
    "        test['new_ind'] = test[c].astype(str)+'_'\n",
    "        count+=1\n",
    "    else:\n",
    "        train['new_ind'] += train[c].astype(str)+'_'\n",
    "        test['new_ind'] += test[c].astype(str)+'_'\n",
    "\n",
    "# 범주형 변수와 new_ind 고유값의 빈도를 파생변수로 생성\n",
    "cat_count_features = []\n",
    "for c in cat_features+['new_ind']:\n",
    "    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n",
    "    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n",
    "    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n",
    "    cat_count_features.append('%s_count'%c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical 변수와 categorical 변수/ new_ind 빈도 및 범주형 변수를 모델 학습에 사용\n",
    "# 나머지는 사용 X\n",
    "train_list = [train[num_features+cat_count_features].values,X_cat,]\n",
    "test_list = [test[num_features+cat_count_features].values,X_t_cat,]\n",
    "\n",
    "# 모델 학습 속도 및 메모리 최적화를 위해 데이터를 Sparse Matrix 형태로 변환\n",
    "X = ssp.hstack(train_list).tocsr()\n",
    "X_test = ssp.hstack(test_list).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYWiFWZOUXVY"
   },
   "outputs": [],
   "source": [
    "# LGBM 파라미터 지정\n",
    "learning_rate = 0.1\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.6\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\", # dart도 돌려보자\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "\n",
    "x_score = []\n",
    "final_cv_train = np.zeros(len(train_label))\n",
    "final_cv_pred = np.zeros(len(test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DNuWTg3jTV75",
    "outputId": "03e92824-18f4-4ded-d425-a5896eb9cee2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.15159\tvalid_0's gini: 0.291863\n",
      "[200]\tvalid_0's binary_logloss: 0.151468\tvalid_0's gini: 0.29491\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.295075\n",
      "0.2950745960037473\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152123\tvalid_0's gini: 0.272679\n",
      "[200]\tvalid_0's binary_logloss: 0.152038\tvalid_0's gini: 0.275581\n",
      "[300]\tvalid_0's binary_logloss: 0.152089\tvalid_0's gini: 0.276195\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.152015\tvalid_0's gini: 0.276851\n",
      "0.27685121636649\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151974\tvalid_0's gini: 0.277978\n",
      "[200]\tvalid_0's binary_logloss: 0.151926\tvalid_0's gini: 0.280307\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.151902\tvalid_0's gini: 0.280395\n",
      "0.2803950421815766\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151832\tvalid_0's gini: 0.283252\n",
      "[200]\tvalid_0's binary_logloss: 0.151762\tvalid_0's gini: 0.285428\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.151744\tvalid_0's gini: 0.285738\n",
      "0.2857383471455344\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151496\tvalid_0's gini: 0.288555\n",
      "[200]\tvalid_0's binary_logloss: 0.151418\tvalid_0's gini: 0.291254\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.151404\tvalid_0's gini: 0.291582\n",
      "0.29158193067359983\n",
      "cv score:\n",
      "0.2858393180467914\n",
      "current score: 0.2858393180467914 1\n",
      "[0.2950745960037473, 0.27685121636649, 0.2803950421815766, 0.2857383471455344, 0.29158193067359983]\n",
      "[189, 224, 139, 194, 183] 185.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151604\tvalid_0's gini: 0.290167\n",
      "[200]\tvalid_0's binary_logloss: 0.15153\tvalid_0's gini: 0.292546\n",
      "[300]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.291396\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's binary_logloss: 0.151501\tvalid_0's gini: 0.293575\n",
      "0.2935750199212115\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152153\tvalid_0's gini: 0.2722\n",
      "[200]\tvalid_0's binary_logloss: 0.152051\tvalid_0's gini: 0.27555\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.152041\tvalid_0's gini: 0.27574\n",
      "0.2757395481512084\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152063\tvalid_0's gini: 0.276269\n",
      "[200]\tvalid_0's binary_logloss: 0.151979\tvalid_0's gini: 0.279146\n",
      "[300]\tvalid_0's binary_logloss: 0.151971\tvalid_0's gini: 0.279805\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's binary_logloss: 0.151958\tvalid_0's gini: 0.279855\n",
      "0.2798546933254257\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151822\tvalid_0's gini: 0.284346\n",
      "[200]\tvalid_0's binary_logloss: 0.151739\tvalid_0's gini: 0.287288\n",
      "[300]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.285641\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.151737\tvalid_0's gini: 0.287408\n",
      "0.2874076703284102\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.290417\n",
      "[200]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.292036\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.151364\tvalid_0's gini: 0.292387\n",
      "0.2923866985336762\n",
      "cv score:\n",
      "0.2857025892457676\n",
      "current score: 0.2872643123582628 2\n",
      "[0.2935750199212115, 0.2757395481512084, 0.2798546933254257, 0.2874076703284102, 0.2923866985336762]\n",
      "[215, 189, 286, 204, 165] 211.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151575\tvalid_0's gini: 0.29241\n",
      "[200]\tvalid_0's binary_logloss: 0.151496\tvalid_0's gini: 0.294357\n",
      "[300]\tvalid_0's binary_logloss: 0.151506\tvalid_0's gini: 0.29466\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's binary_logloss: 0.15147\tvalid_0's gini: 0.29552\n",
      "0.2955204222194154\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152099\tvalid_0's gini: 0.275929\n",
      "[200]\tvalid_0's binary_logloss: 0.152031\tvalid_0's gini: 0.278335\n",
      "[300]\tvalid_0's binary_logloss: 0.152056\tvalid_0's gini: 0.278427\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's binary_logloss: 0.152012\tvalid_0's gini: 0.279375\n",
      "0.27937492210177034\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152058\tvalid_0's gini: 0.275752\n",
      "[200]\tvalid_0's binary_logloss: 0.152014\tvalid_0's gini: 0.278342\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's binary_logloss: 0.151987\tvalid_0's gini: 0.278225\n",
      "0.278224639267951\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151804\tvalid_0's gini: 0.284144\n",
      "[200]\tvalid_0's binary_logloss: 0.151849\tvalid_0's gini: 0.283216\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.151771\tvalid_0's gini: 0.285191\n",
      "0.2851906999343939\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151492\tvalid_0's gini: 0.28916\n",
      "[200]\tvalid_0's binary_logloss: 0.151414\tvalid_0's gini: 0.29076\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.151409\tvalid_0's gini: 0.29079\n",
      "0.290789901505339\n",
      "cv score:\n",
      "0.2857014342774277\n",
      "current score: 0.28773280818590957 3\n",
      "[0.2955204222194154, 0.27937492210177034, 0.278224639267951, 0.2851906999343939, 0.290789901505339]\n",
      "[243, 255, 162, 137, 197] 198.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151582\tvalid_0's gini: 0.2928\n",
      "[200]\tvalid_0's binary_logloss: 0.151494\tvalid_0's gini: 0.294292\n",
      "[300]\tvalid_0's binary_logloss: 0.151533\tvalid_0's gini: 0.293455\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.151474\tvalid_0's gini: 0.294864\n",
      "0.29486409196133345\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152092\tvalid_0's gini: 0.274761\n",
      "[200]\tvalid_0's binary_logloss: 0.152045\tvalid_0's gini: 0.276197\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's binary_logloss: 0.152026\tvalid_0's gini: 0.276538\n",
      "0.27653796783422363\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152083\tvalid_0's gini: 0.275746\n",
      "[200]\tvalid_0's binary_logloss: 0.151972\tvalid_0's gini: 0.279671\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's binary_logloss: 0.151969\tvalid_0's gini: 0.279727\n",
      "0.2797265104461791\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151804\tvalid_0's gini: 0.284287\n",
      "[200]\tvalid_0's binary_logloss: 0.151768\tvalid_0's gini: 0.285203\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.285923\n",
      "0.2859227849178558\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151413\tvalid_0's gini: 0.291423\n",
      "[200]\tvalid_0's binary_logloss: 0.1513\tvalid_0's gini: 0.294989\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.151293\tvalid_0's gini: 0.29545\n",
      "0.2954495502123637\n",
      "cv score:\n",
      "0.28642219769508487\n",
      "current score: 0.28809797959747097 4\n",
      "[0.29486409196133345, 0.27653796783422363, 0.2797265104461791, 0.2859227849178558, 0.2954495502123637]\n",
      "[210, 173, 196, 182, 164] 185.0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151593\tvalid_0's gini: 0.291283\n",
      "[200]\tvalid_0's binary_logloss: 0.151481\tvalid_0's gini: 0.294599\n",
      "[300]\tvalid_0's binary_logloss: 0.151508\tvalid_0's gini: 0.29454\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.151463\tvalid_0's gini: 0.295229\n",
      "0.2952286363874112\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152107\tvalid_0's gini: 0.27518\n",
      "[200]\tvalid_0's binary_logloss: 0.152068\tvalid_0's gini: 0.277489\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.152021\tvalid_0's gini: 0.278142\n",
      "0.27814179935499217\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152046\tvalid_0's gini: 0.276367\n",
      "[200]\tvalid_0's binary_logloss: 0.152002\tvalid_0's gini: 0.278679\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.151985\tvalid_0's gini: 0.278726\n",
      "0.2787257707789949\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151801\tvalid_0's gini: 0.284706\n",
      "[200]\tvalid_0's binary_logloss: 0.151754\tvalid_0's gini: 0.286656\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.151743\tvalid_0's gini: 0.286936\n",
      "0.2869359770649055\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151442\tvalid_0's gini: 0.290857\n",
      "[200]\tvalid_0's binary_logloss: 0.151343\tvalid_0's gini: 0.293735\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.151337\tvalid_0's gini: 0.29401\n",
      "0.29401039951838737\n",
      "cv score:\n",
      "0.28657299171180295\n",
      "current score: 0.28838512642760716 5\n",
      "[0.2952286363874112, 0.27814179935499217, 0.2787257707789949, 0.2869359770649055, 0.29401039951838737]\n",
      "[226, 153, 141, 146, 197] 172.6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151527\tvalid_0's gini: 0.29366\n",
      "[200]\tvalid_0's binary_logloss: 0.151462\tvalid_0's gini: 0.295402\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.151451\tvalid_0's gini: 0.295517\n",
      "0.2955173802302563\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152087\tvalid_0's gini: 0.274662\n",
      "[200]\tvalid_0's binary_logloss: 0.152011\tvalid_0's gini: 0.277844\n",
      "[300]\tvalid_0's binary_logloss: 0.1521\tvalid_0's gini: 0.276825\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's binary_logloss: 0.151991\tvalid_0's gini: 0.279094\n",
      "0.2790944965119757\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152076\tvalid_0's gini: 0.275285\n",
      "[200]\tvalid_0's binary_logloss: 0.15199\tvalid_0's gini: 0.278601\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.15197\tvalid_0's gini: 0.279352\n",
      "0.2793522273715637\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.1518\tvalid_0's gini: 0.283767\n",
      "[200]\tvalid_0's binary_logloss: 0.151817\tvalid_0's gini: 0.284448\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.151766\tvalid_0's gini: 0.285666\n",
      "0.28566634339791586\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151444\tvalid_0's gini: 0.290738\n",
      "[200]\tvalid_0's binary_logloss: 0.151397\tvalid_0's gini: 0.291561\n",
      "[300]\tvalid_0's binary_logloss: 0.151389\tvalid_0's gini: 0.292225\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's binary_logloss: 0.151365\tvalid_0's gini: 0.293066\n",
      "0.2930658556591247\n",
      "cv score:\n",
      "0.2864549941342671\n",
      "current score: 0.28857188183432725 6\n",
      "[0.2955173802302563, 0.2790944965119757, 0.2793522273715637, 0.28566634339791586, 0.2930658556591247]\n",
      "[190, 232, 142, 157, 241] 192.4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151601\tvalid_0's gini: 0.292595\n",
      "[200]\tvalid_0's binary_logloss: 0.151564\tvalid_0's gini: 0.292948\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.151557\tvalid_0's gini: 0.293497\n",
      "0.2934967238620638\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152125\tvalid_0's gini: 0.274634\n",
      "[200]\tvalid_0's binary_logloss: 0.152091\tvalid_0's gini: 0.276014\n",
      "[300]\tvalid_0's binary_logloss: 0.152138\tvalid_0's gini: 0.275317\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's binary_logloss: 0.152076\tvalid_0's gini: 0.276689\n",
      "0.2766889260439311\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152069\tvalid_0's gini: 0.276395\n",
      "[200]\tvalid_0's binary_logloss: 0.151981\tvalid_0's gini: 0.279482\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.151975\tvalid_0's gini: 0.279621\n",
      "0.27962114975464575\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151844\tvalid_0's gini: 0.282616\n",
      "[200]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.283846\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.151787\tvalid_0's gini: 0.284275\n",
      "0.2842749406964166\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151533\tvalid_0's gini: 0.288513\n",
      "[200]\tvalid_0's binary_logloss: 0.151429\tvalid_0's gini: 0.291301\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.151425\tvalid_0's gini: 0.291478\n",
      "0.2914784981219782\n",
      "cv score:\n",
      "0.2849306183737817\n",
      "current score: 0.28846905268024015 7\n",
      "[0.2934967238620638, 0.2766889260439311, 0.27962114975464575, 0.2842749406964166, 0.2914784981219782]\n",
      "[157, 250, 184, 157, 176] 184.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151549\tvalid_0's gini: 0.292545\n",
      "[200]\tvalid_0's binary_logloss: 0.151465\tvalid_0's gini: 0.294302\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.151462\tvalid_0's gini: 0.294758\n",
      "0.29475795989306464\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152114\tvalid_0's gini: 0.274395\n",
      "[200]\tvalid_0's binary_logloss: 0.152046\tvalid_0's gini: 0.277096\n",
      "[300]\tvalid_0's binary_logloss: 0.15206\tvalid_0's gini: 0.277783\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's binary_logloss: 0.152002\tvalid_0's gini: 0.278437\n",
      "0.2784373625579469\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152055\tvalid_0's gini: 0.275678\n",
      "[200]\tvalid_0's binary_logloss: 0.152013\tvalid_0's gini: 0.27778\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.15201\tvalid_0's gini: 0.276936\n",
      "0.2769356036803868\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151814\tvalid_0's gini: 0.28414\n",
      "[200]\tvalid_0's binary_logloss: 0.151793\tvalid_0's gini: 0.284928\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.151768\tvalid_0's gini: 0.285197\n",
      "0.2851969005026813\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.291002\n",
      "[200]\tvalid_0's binary_logloss: 0.151314\tvalid_0's gini: 0.294441\n",
      "[300]\tvalid_0's binary_logloss: 0.151357\tvalid_0's gini: 0.293188\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's binary_logloss: 0.151313\tvalid_0's gini: 0.294627\n",
      "0.2946268999615682\n",
      "cv score:\n",
      "0.28591254303953334\n",
      "current score: 0.2885036028709306 8\n",
      "[0.29475795989306464, 0.2784373625579469, 0.2769356036803868, 0.2851969005026813, 0.2946268999615682]\n",
      "[177, 229, 129, 141, 222] 179.6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151608\tvalid_0's gini: 0.29135\n",
      "[200]\tvalid_0's binary_logloss: 0.151545\tvalid_0's gini: 0.29309\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.151536\tvalid_0's gini: 0.293389\n",
      "0.2933894344716314\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152108\tvalid_0's gini: 0.274555\n",
      "[200]\tvalid_0's binary_logloss: 0.152052\tvalid_0's gini: 0.276202\n",
      "[300]\tvalid_0's binary_logloss: 0.152069\tvalid_0's gini: 0.276647\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's binary_logloss: 0.152034\tvalid_0's gini: 0.277313\n",
      "0.2773128673553526\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152087\tvalid_0's gini: 0.275393\n",
      "[200]\tvalid_0's binary_logloss: 0.152047\tvalid_0's gini: 0.277124\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.152039\tvalid_0's gini: 0.277116\n",
      "0.27711602276102837\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151775\tvalid_0's gini: 0.285865\n",
      "[200]\tvalid_0's binary_logloss: 0.151751\tvalid_0's gini: 0.286686\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.151725\tvalid_0's gini: 0.287102\n",
      "0.28710240787255004\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151478\tvalid_0's gini: 0.289751\n",
      "[200]\tvalid_0's binary_logloss: 0.151422\tvalid_0's gini: 0.290651\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.151427\tvalid_0's gini: 0.291024\n",
      "0.2910241608237578\n",
      "cv score:\n",
      "0.2850760894090657\n",
      "current score: 0.28843619017397537 9\n",
      "[0.2933894344716314, 0.2773128673553526, 0.27711602276102837, 0.28710240787255004, 0.2910241608237578]\n",
      "[182, 255, 129, 166, 164] 179.2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151548\tvalid_0's gini: 0.292315\n",
      "[200]\tvalid_0's binary_logloss: 0.151452\tvalid_0's gini: 0.294847\n",
      "[300]\tvalid_0's binary_logloss: 0.151454\tvalid_0's gini: 0.295291\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's binary_logloss: 0.151437\tvalid_0's gini: 0.295568\n",
      "0.2955676674856543\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152158\tvalid_0's gini: 0.273093\n",
      "[200]\tvalid_0's binary_logloss: 0.152089\tvalid_0's gini: 0.276147\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's binary_logloss: 0.152079\tvalid_0's gini: 0.276243\n",
      "0.276242645740053\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152047\tvalid_0's gini: 0.276454\n",
      "[200]\tvalid_0's binary_logloss: 0.151962\tvalid_0's gini: 0.280027\n",
      "[300]\tvalid_0's binary_logloss: 0.151985\tvalid_0's gini: 0.279929\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.151938\tvalid_0's gini: 0.280751\n",
      "0.2807507596195159\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151818\tvalid_0's gini: 0.283789\n",
      "[200]\tvalid_0's binary_logloss: 0.15181\tvalid_0's gini: 0.284446\n",
      "[300]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.285261\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's binary_logloss: 0.15179\tvalid_0's gini: 0.285349\n",
      "0.2853491740827971\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.287214\n",
      "[200]\tvalid_0's binary_logloss: 0.151501\tvalid_0's gini: 0.288273\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.289234\n",
      "0.28923363521695494\n",
      "cv score:\n",
      "0.28534116886916905\n",
      "current score: 0.28844964503270565 10\n",
      "[0.2955676674856543, 0.276242645740053, 0.2807507596195159, 0.2853491740827971, 0.28923363521695494]\n",
      "[239, 196, 212, 248, 149] 208.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151545\tvalid_0's gini: 0.292477\n",
      "[200]\tvalid_0's binary_logloss: 0.151517\tvalid_0's gini: 0.293056\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.151498\tvalid_0's gini: 0.293759\n",
      "0.29375880911035007\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152093\tvalid_0's gini: 0.274525\n",
      "[200]\tvalid_0's binary_logloss: 0.151989\tvalid_0's gini: 0.278548\n",
      "[300]\tvalid_0's binary_logloss: 0.152041\tvalid_0's gini: 0.278658\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's binary_logloss: 0.151977\tvalid_0's gini: 0.279613\n",
      "0.27961328626418364\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152074\tvalid_0's gini: 0.27583\n",
      "[200]\tvalid_0's binary_logloss: 0.152013\tvalid_0's gini: 0.278264\n",
      "[300]\tvalid_0's binary_logloss: 0.152015\tvalid_0's gini: 0.278326\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's binary_logloss: 0.151993\tvalid_0's gini: 0.278944\n",
      "0.2789441772664835\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.283863\n",
      "[200]\tvalid_0's binary_logloss: 0.151833\tvalid_0's gini: 0.284569\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's binary_logloss: 0.151813\tvalid_0's gini: 0.283995\n",
      "0.2839952601055715\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151509\tvalid_0's gini: 0.287653\n",
      "[200]\tvalid_0's binary_logloss: 0.15141\tvalid_0's gini: 0.290869\n",
      "[300]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.289624\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.151402\tvalid_0's gini: 0.291042\n",
      "0.2910419106034895\n",
      "cv score:\n",
      "0.28532266076273827\n",
      "current score: 0.2884465453452323 11\n",
      "[0.29375880911035007, 0.27961328626418364, 0.2789441772664835, 0.2839952601055715, 0.2910419106034895]\n",
      "[177, 225, 258, 116, 204] 196.0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151543\tvalid_0's gini: 0.293201\n",
      "[200]\tvalid_0's binary_logloss: 0.151467\tvalid_0's gini: 0.295595\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.15144\tvalid_0's gini: 0.295968\n",
      "0.2959683782293427\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152227\tvalid_0's gini: 0.271808\n",
      "[200]\tvalid_0's binary_logloss: 0.152133\tvalid_0's gini: 0.275909\n",
      "[300]\tvalid_0's binary_logloss: 0.152186\tvalid_0's gini: 0.276224\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.152119\tvalid_0's gini: 0.276549\n",
      "0.27654868110119585\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152017\tvalid_0's gini: 0.277246\n",
      "[200]\tvalid_0's binary_logloss: 0.151937\tvalid_0's gini: 0.280069\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.151935\tvalid_0's gini: 0.280143\n",
      "0.2801430696339272\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151803\tvalid_0's gini: 0.28397\n",
      "[200]\tvalid_0's binary_logloss: 0.151783\tvalid_0's gini: 0.285072\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's binary_logloss: 0.151753\tvalid_0's gini: 0.285496\n",
      "0.2854960789271823\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.290377\n",
      "[200]\tvalid_0's binary_logloss: 0.151374\tvalid_0's gini: 0.293165\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.151373\tvalid_0's gini: 0.29336\n",
      "0.2933600671993721\n",
      "cv score:\n",
      "0.28618096957698835\n",
      "current score: 0.2885010259332192 12\n",
      "[0.2959683782293427, 0.27654868110119585, 0.2801430696339272, 0.2854960789271823, 0.2933600671993721]\n",
      "[154, 218, 198, 171, 158] 179.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151549\tvalid_0's gini: 0.29324\n",
      "[200]\tvalid_0's binary_logloss: 0.151445\tvalid_0's gini: 0.2965\n",
      "[300]\tvalid_0's binary_logloss: 0.151467\tvalid_0's gini: 0.295659\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.151433\tvalid_0's gini: 0.296886\n",
      "0.2968862592779062\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152137\tvalid_0's gini: 0.273446\n",
      "[200]\tvalid_0's binary_logloss: 0.152054\tvalid_0's gini: 0.276994\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.152043\tvalid_0's gini: 0.277307\n",
      "0.2773070405597376\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152119\tvalid_0's gini: 0.274704\n",
      "[200]\tvalid_0's binary_logloss: 0.152005\tvalid_0's gini: 0.278497\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.151999\tvalid_0's gini: 0.278625\n",
      "0.2786247309489958\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151822\tvalid_0's gini: 0.284249\n",
      "[200]\tvalid_0's binary_logloss: 0.151776\tvalid_0's gini: 0.28493\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.151772\tvalid_0's gini: 0.285764\n",
      "0.2857639290105496\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.15151\tvalid_0's gini: 0.287782\n",
      "[200]\tvalid_0's binary_logloss: 0.151392\tvalid_0's gini: 0.291393\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.151386\tvalid_0's gini: 0.291615\n",
      "0.291615039216776\n",
      "cv score:\n",
      "0.2859750728807769\n",
      "current score: 0.28851836010314574 13\n",
      "[0.2968862592779062, 0.2773070405597376, 0.2786247309489958, 0.2857639290105496, 0.291615039216776]\n",
      "[212, 194, 198, 155, 190] 189.8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151548\tvalid_0's gini: 0.293495\n",
      "[200]\tvalid_0's binary_logloss: 0.151433\tvalid_0's gini: 0.296269\n",
      "[300]\tvalid_0's binary_logloss: 0.151436\tvalid_0's gini: 0.295894\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's binary_logloss: 0.151419\tvalid_0's gini: 0.296735\n",
      "0.29673532116059737\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152149\tvalid_0's gini: 0.272677\n",
      "[200]\tvalid_0's binary_logloss: 0.152083\tvalid_0's gini: 0.27552\n",
      "[300]\tvalid_0's binary_logloss: 0.152116\tvalid_0's gini: 0.275927\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's binary_logloss: 0.152064\tvalid_0's gini: 0.276679\n",
      "0.27667851014445916\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152087\tvalid_0's gini: 0.276195\n",
      "[200]\tvalid_0's binary_logloss: 0.151996\tvalid_0's gini: 0.279471\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.151977\tvalid_0's gini: 0.280084\n",
      "0.28008369094793084\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151821\tvalid_0's gini: 0.284589\n",
      "[200]\tvalid_0's binary_logloss: 0.151836\tvalid_0's gini: 0.284824\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.151767\tvalid_0's gini: 0.28618\n",
      "0.28617958408561006\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151454\tvalid_0's gini: 0.290433\n",
      "[200]\tvalid_0's binary_logloss: 0.151403\tvalid_0's gini: 0.292204\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.151387\tvalid_0's gini: 0.292099\n",
      "0.29209911754279666\n",
      "cv score:\n",
      "0.28622141629497744\n",
      "current score: 0.2885596390091784 14\n",
      "[0.29673532116059737, 0.27667851014445916, 0.28008369094793084, 0.28617958408561006, 0.29209911754279666]\n",
      "[237, 239, 188, 131, 157] 190.4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151518\tvalid_0's gini: 0.294144\n",
      "[200]\tvalid_0's binary_logloss: 0.151461\tvalid_0's gini: 0.295541\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.151463\tvalid_0's gini: 0.295874\n",
      "0.2958735461260875\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152109\tvalid_0's gini: 0.274049\n",
      "[200]\tvalid_0's binary_logloss: 0.152067\tvalid_0's gini: 0.275319\n",
      "[300]\tvalid_0's binary_logloss: 0.152101\tvalid_0's gini: 0.275549\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's binary_logloss: 0.152032\tvalid_0's gini: 0.27689\n",
      "0.27688973751322515\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.15212\tvalid_0's gini: 0.274505\n",
      "[200]\tvalid_0's binary_logloss: 0.152001\tvalid_0's gini: 0.279239\n",
      "[300]\tvalid_0's binary_logloss: 0.152056\tvalid_0's gini: 0.278137\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's binary_logloss: 0.151992\tvalid_0's gini: 0.279543\n",
      "0.27954340238287106\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151841\tvalid_0's gini: 0.283119\n",
      "[200]\tvalid_0's binary_logloss: 0.151845\tvalid_0's gini: 0.283338\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.151786\tvalid_0's gini: 0.285047\n",
      "0.2850468813093507\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151476\tvalid_0's gini: 0.290042\n",
      "[200]\tvalid_0's binary_logloss: 0.151407\tvalid_0's gini: 0.291736\n",
      "[300]\tvalid_0's binary_logloss: 0.151469\tvalid_0's gini: 0.290186\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.151405\tvalid_0's gini: 0.291903\n",
      "0.29190300598507335\n",
      "cv score:\n",
      "0.2856714472163492\n",
      "current score: 0.2885496480909848 15\n",
      "[0.2958735461260875, 0.27688973751322515, 0.27954340238287106, 0.2850468813093507, 0.29190300598507335]\n",
      "[148, 240, 219, 154, 207] 193.6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151601\tvalid_0's gini: 0.292096\n",
      "[200]\tvalid_0's binary_logloss: 0.151496\tvalid_0's gini: 0.294731\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.151489\tvalid_0's gini: 0.294925\n",
      "0.29492506837282534\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152046\tvalid_0's gini: 0.276157\n",
      "[200]\tvalid_0's binary_logloss: 0.151952\tvalid_0's gini: 0.279624\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's binary_logloss: 0.151945\tvalid_0's gini: 0.279831\n",
      "0.2798313410300186\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152063\tvalid_0's gini: 0.275495\n",
      "[200]\tvalid_0's binary_logloss: 0.151991\tvalid_0's gini: 0.27821\n",
      "[300]\tvalid_0's binary_logloss: 0.152031\tvalid_0's gini: 0.277822\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's binary_logloss: 0.15197\tvalid_0's gini: 0.278833\n",
      "0.27883290402860883\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151816\tvalid_0's gini: 0.284155\n",
      "[200]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.284813\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.151794\tvalid_0's gini: 0.284781\n",
      "0.2847811288906925\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.151512\tvalid_0's gini: 0.28849\n",
      "[200]\tvalid_0's binary_logloss: 0.151469\tvalid_0's gini: 0.290052\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.151453\tvalid_0's gini: 0.290385\n",
      "0.2903850321239166\n",
      "cv score:\n",
      "0.2856285709657942\n",
      "current score: 0.28854785993958426 16\n",
      "[0.29492506837282534, 0.2798313410300186, 0.27883290402860883, 0.2847811288906925, 0.2903850321239166]\n",
      "[197, 192, 229, 151, 144] 182.6\n",
      "[0.2858393180467914, 0.2857025892457676, 0.2857014342774277, 0.28642219769508487, 0.28657299171180295, 0.2864549941342671, 0.2849306183737817, 0.28591254303953334, 0.2850760894090657, 0.28534116886916905, 0.28532266076273827, 0.28618096957698835, 0.2859750728807769, 0.28622141629497744, 0.2856714472163492, 0.2856285709657942]\n"
     ]
    }
   ],
   "source": [
    "# kfold 정의\n",
    "# Stratified 5-Fold 내부 교차검증\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "\n",
    "# 총 16번의 seed 값으로 학습을 돌려, 평균 값을 최종 예측 결과물로 사용\n",
    "# 시드값이 많을 수록 랜덤 요소로 인한 분산을 줄일 수 있음!\n",
    "# 하지만 시드값을 너무 크게 주면 학습이 오래걸림\n",
    "for s in range(16):\n",
    "    cv_train = np.zeros(len(train_label))\n",
    "    cv_pred = np.zeros(len(test_id))\n",
    "\n",
    "    params['seed'] = s\n",
    "\n",
    "    if cv_only:\n",
    "        kf = kfold.split(X, train_label)\n",
    "\n",
    "        best_trees = []\n",
    "        fold_scores = []\n",
    "\n",
    "        for i, (train_fold, validate) in enumerate(kf):\n",
    "            X_train, X_validate, label_train, label_validate = \\\n",
    "                X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n",
    "            dtrain = lgbm.Dataset(X_train, label_train)\n",
    "            dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "            bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n",
    "                            early_stopping_rounds=100)\n",
    "            best_trees.append(bst.best_iteration)\n",
    "            cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "            cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "            score = Gini(label_validate, cv_train[validate])\n",
    "            print(score)\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        cv_pred /= NFOLDS\n",
    "        final_cv_train += cv_train\n",
    "        final_cv_pred += cv_pred\n",
    "\n",
    "        print(\"cv score:\")\n",
    "        print(Gini(train_label, cv_train))\n",
    "        print(\"current score:\", Gini(train_label, final_cv_train / (s + 1.)), s+1)\n",
    "        print(fold_scores)\n",
    "        print(best_trees, np.mean(best_trees))\n",
    "\n",
    "        x_score.append(Gini(train_label, cv_train))\n",
    "\n",
    "print(x_score)\n",
    "pd.DataFrame({'id': test_id, 'target': final_cv_pred / 16.}).to_csv('/content/gdrive/My Drive/보아즈미니플젝/lgbm0819_1.csv', index=False)\n",
    "pd.DataFrame({'id': train_id, 'target': final_cv_train / 16.}).to_csv('/content/gdrive/My Drive/보아즈미니플젝/lgbm0819_train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lgbm290.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
